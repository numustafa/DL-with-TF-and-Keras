{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2c3717",
   "metadata": {
    "id": "fa2c3717"
   },
   "source": [
    "<h1 style=\"font-size:30px;\">Introduction to the TensorFlow Data API</h1>\n",
    "\n",
    "Thus far, we have been using the `image_dataset_from_directory()` class in TensorFlow to build data pipelines for training deep learning models. `image_dataset_from_directory()` is easy and straightforward to use but has some performance limitations and is not as flexible as other methods that can be used to create data pipelines. In this notebook, we will introduce how to use the <a href=\"https://www.tensorflow.org/guide/data\" target=_blank>TensorFlow Data API</a> (`tf.data`), directly which has more flexibility and performance to handle larger datasets and a wide range of data formats. \n",
    "\n",
    "Specifically, we will create data pipelines using data that resides in memory and from data that resides on the filesystem. For this purpose, we will use the <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset\" target=_blank>tf.data.Dataset</a> class which has the following methods for processing data from memory and from the file system:\n",
    "\n",
    "1. `tf.data.Dataset.from_tensor_slices()`\n",
    "2. `tf.data.Dataset.list_files()` and `tf.data.Dataset.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94abcff",
   "metadata": {
    "id": "a94abcff"
   },
   "source": [
    "\n",
    "\n",
    "## Table of Contents\n",
    "* [1 System Configuration](#1-System-Configuration)\n",
    "* [2 Training and Dataset Configurations](#2-Training-and-Dataset-Configurations)\n",
    "* [3 Download and Extract the Dataset](#3-Download-and-Extract-the-Dataset)\n",
    "* [4 LeNet5 Model](#4-LeNet5-Model)\n",
    "* [5 Data Pipeline from Memory](#5-Data-Pipeline-from-Memory)\n",
    "* [6 Data Pipeline from File System](#6-Data-Pipeline-from-File-System)\n",
    "* [7 Training Plots](#7-Training-Plots)\n",
    "* [8 Conclusion](#8-Conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11fd6d",
   "metadata": {
    "id": "cb11fd6d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import zipfile\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Conv2D, Activation, Input,\n",
    "                                     MaxPool2D, Flatten, Dense)\n",
    "\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "block_plot = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b06120",
   "metadata": {
    "id": "87b06120"
   },
   "source": [
    "## 1 System Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3357517",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3357517",
    "outputId": "8c2d959f-4dd8-4c15-a3b6-a28b49222fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "def system_config(SEED_VALUE):\n",
    "\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    tf.random.set_seed(SEED_VALUE)\n",
    "    \n",
    "    # Get list of GPUs.\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(gpu_devices)\n",
    "    \n",
    "    if len(gpu_devices) > 0:\n",
    "        print('Using GPU')\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "        os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n",
    "        \n",
    "        # If there are any gpu devices, use first gpu.\n",
    "        tf.config.experimental.set_visible_devices(gpu_devices[0], 'GPU')\n",
    "        \n",
    "        # Grow the memory usage as it is needed by the process.\n",
    "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "        \n",
    "        # Enable using cudNN.\n",
    "        os.environ['TF_USE_CUDNN'] = \"true\"\n",
    "    else:\n",
    "        print('Using CPU')\n",
    "\n",
    "system_config(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1679b7d",
   "metadata": {
    "id": "d1679b7d"
   },
   "source": [
    "## 2 Training and Dataset Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa16ab",
   "metadata": {
    "id": "80fa16ab"
   },
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    NUM_CLASSES: int = 10\n",
    "    IMG_HEIGHT:  int = 32\n",
    "    IMG_WIDTH:   int = 32\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE:      int = 16\n",
    "    EPOCHS:          int = 11\n",
    "    LEARNING_RATE: float = 0.0005\n",
    "    ROOT_LOG_DIR         = \"./logs\"\n",
    "    ROOT_CHECKPOINT_DIR  = \"./models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e76643",
   "metadata": {
    "id": "27e76643"
   },
   "source": [
    "## 3 Download and Extract the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3e78a",
   "metadata": {
    "id": "b4f3e78a"
   },
   "source": [
    "As mentioned above, we will demonstrate how to create data pipelines from data that resides in memory and from data that resides on the file system. In this section, we will download the CIFAR10 dataset to our file system so it is avaialble for us to process. This CIFAR10 dataset has been downloaded from <a href=\"https://pjreddie.com/projects/cifar-10-dataset-mirror/\" target=_blank>Joseph Redmon's website</a> and modified such that all the images are in their respective class folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935620a0",
   "metadata": {
    "id": "935620a0"
   },
   "outputs": [],
   "source": [
    "def download_file(url, save_name):\n",
    "    url = url\n",
    "    if not os.path.exists(save_name):\n",
    "        file = requests.get(url)\n",
    "        open(save_name, 'wb').write(file.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9dd5b",
   "metadata": {
    "id": "20e9dd5b"
   },
   "outputs": [],
   "source": [
    "def unzip(zip_file=None):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file) as z:\n",
    "            z.extractall(\"./\")\n",
    "            print(\"Extracted all\")\n",
    "    except:\n",
    "        print(\"Invalid file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6634d46",
   "metadata": {
    "id": "d6634d46",
    "outputId": "dd5a0d4a-d875-4a61-ff77-688fe8616ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted all\n"
     ]
    }
   ],
   "source": [
    "download_file(\n",
    "    'https://www.dropbox.com/s/6jrhe7uu4a4qxbn/cifar10.zip?dl=1',\n",
    "    'cifar10.zip'\n",
    ")\n",
    "    \n",
    "unzip(zip_file='cifar10.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ffd8d",
   "metadata": {
    "id": "a48ffd8d"
   },
   "source": [
    "```\n",
    "cifar10\n",
    "├── labels.txt\n",
    "├── test\n",
    "│   ├── airplane\n",
    "│   ├── automobile\n",
    "│   ├── bird\n",
    "│   ├── cat\n",
    "│   ├── deer\n",
    "│   ├── dog\n",
    "│   ├── frog\n",
    "│   ├── horse\n",
    "│   ├── ship\n",
    "│   └── truck\n",
    "└── train\n",
    "    ├── airplane\n",
    "    ├── automobile\n",
    "    ├── bird\n",
    "    ├── cat\n",
    "    ├── deer\n",
    "    ├── dog\n",
    "    ├── frog\n",
    "    ├── horse\n",
    "    ├── ship\n",
    "    └── truck\n",
    "```\n",
    "\n",
    "As you can see, we have `train` and `test` subdirectories which in turn contain sub-directories for each class in the CIFAR10 dataset. All the class folders contain the respective images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854680bb",
   "metadata": {
    "id": "854680bb"
   },
   "source": [
    "## 4 LeNet5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1199261",
   "metadata": {
    "id": "d1199261"
   },
   "outputs": [],
   "source": [
    "def LeNet5_model(num_classes, shape, print_model_summary=True):\n",
    "\n",
    "    inputs = Input(shape=shape)\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # First convolutional Layer + pooling\n",
    "    # -------------------------------------\n",
    "    x = Conv2D(6, 5, padding='valid')(inputs)              # input size = (32, 32), output size = (28, 28)\n",
    "    x = Activation(\"relu\")(x)                              # output size = (28, 28)\n",
    "    x = MaxPool2D()(x)                                     # output size = (14, 14)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # Second convolutional layer + pooling \n",
    "    # -------------------------------------\n",
    "    x = Conv2D(16, 5, padding='valid')(x)                  # input size = (14, 14), output size = (10, 10)\n",
    "    x = Activation('relu')(x)                              # output size = (10, 10)\n",
    "    feature_extractor_output = MaxPool2D()(x)              # output size = (5, 5)\n",
    "\n",
    "    # Flatten.\n",
    "    flattened = Flatten()(feature_extractor_output)        # 5 * 5 * 16 -> 400\n",
    "\n",
    "    # ------------------------- \n",
    "    # Fully connected layers.\n",
    "    # -------------------------\n",
    "    x = Dense(120, activation='relu')(flattened)           # 400 -> 120\n",
    "    x = Dense(84, activation='relu')(x)                    # 120 -> 84\n",
    "    \n",
    "    # Softmax output layer.\n",
    "    headout = Dense(num_classes, activation=\"softmax\")(x)  # 84 -> 10\n",
    "    \n",
    "    # Create model.\n",
    "    model = Model(inputs=inputs, outputs=headout, name='LeNet5')\n",
    "    \n",
    "    if print_model_summary:\n",
    "        model.summary()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c84dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc5c84dc",
    "outputId": "abccabd8-ea42-483a-e221-30fcc042c0d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 28, 28, 6)         0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10, 10, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 12:24:01.773852: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5_model(num_classes=DatasetConfig.NUM_CLASSES, \n",
    "                     shape=(DatasetConfig.IMG_HEIGHT, DatasetConfig.IMG_WIDTH, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea119f",
   "metadata": {
    "id": "bcea119f"
   },
   "source": [
    "## 5 Data Pipeline from Memory \n",
    "\n",
    "In this section, we are going to demonstrate how to create a data pipeline from data that resides in memory. For that purpose, we will load the CIFAR10 dataset into memory and then build a data pipeline from the data in memory. As a preview, we will create two convenience functions and use them to build the pipeline. The first function `cifar10_from_keras()` will load the dataset into memory, and the second function `prepare_input_pipeline()` will use `tf.data.Dataset.from_tensor_slices()` to build the data pipeline.\n",
    "\n",
    "#### Load the CIFAR10 data into memory\n",
    "`(X_train, y_train), (X_valid, y_test) = cifar10_from_keras()`\n",
    "\n",
    "#### Prepare the tf.data pipeline data from memory\n",
    "`train_ds = prepare_input_pipeline(X_train, y_train)` <br>\n",
    "`valid_ds = prepare_input_pipeline(X_test, y_test)`\n",
    "\n",
    "With that preview, let's now take a look at each of these functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1037081",
   "metadata": {
    "id": "e1037081"
   },
   "source": [
    "### 5.1 Function to Load Dataset in Memory\n",
    "\n",
    "The function below loads the CIFAR10 dataset from `Keras.datasets` into NumPy arrays and performs some pre-processing on the data to normalize the images and convert the labels to a one-hot encoded representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07205fb4",
   "metadata": {
    "id": "07205fb4"
   },
   "outputs": [],
   "source": [
    "# Function to load the CIFAR10 dataset from Keras Datasets.\n",
    "def cifar10_from_keras():\n",
    "    \n",
    "    # load_data() returns NumPy arrays with Shape: (samples, height, width, channels)\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    \n",
    "    # Normalize images.\n",
    "    X_train = X_train / 255.\n",
    "    X_test = X_test / 255.\n",
    "    \n",
    "    num_classes = y_train.shape[-1]\n",
    "    y_train = to_categorical(y_train, DatasetConfig.NUM_CLASSES)\n",
    "    y_test = to_categorical(y_test, DatasetConfig.NUM_CLASSES)\n",
    "        \n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9dcc5",
   "metadata": {
    "id": "13b9dcc5"
   },
   "source": [
    "### 5.2 Function to Create Pre-fetch Dataset from Memory\n",
    "\n",
    "The next function below uses `tf.data.Dataset.from_tensor_slices()` to load the image and label tensors into a dataset whose elements are slices of the given tensors. The inputs are sliced along their first dimension, which preserves the structure of the input, removing the first dimension of each tensor and using it as the dataset dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879cc0c",
   "metadata": {
    "id": "6879cc0c"
   },
   "outputs": [],
   "source": [
    "def prepare_input_pipeline(x, y):\n",
    "    \n",
    "    # Create a TensorSliceDataset object.\n",
    "    # x:  (samples, height, width, channels)\n",
    "    # y:  (samples, classes)\n",
    "    # ds: {samples} ((height, width, channels), (classes,))\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    \n",
    "    # Optional, but highly recommended for improved performance. \n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=512)\n",
    "    ds = ds.batch(TrainingConfig.BATCH_SIZE)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954e622",
   "metadata": {
    "id": "0954e622"
   },
   "source": [
    "Ok, now let's try to understand what is happening in the above code block. In the `prepare_input_pipeline()`:\n",
    "* We pass the images and labels as NumPy arrays to the function.\n",
    "* As discussed we use the `tf.data.Dataset.from_tensor_slices` to prepare the `dataset`. This contains the data examples as images and their corresponding labels.\n",
    "\n",
    "The next few lines of code are optional but can improve performance.\n",
    "* `cache()`: Before loading the data in memory and shuffling it, we cache the data. This will improve performance by minimizing operations (like data reading) from being executed during each epoch.\n",
    "* `shuffle`:  Randomly shuffles the elements of the dataset. `buffer_size` signifies how many data points to use at once. You need to be a bit careful with this as too large a `buffer_size` can potentially freeze your system if you run out of memory. 512, or 1024 provides a good balance.\n",
    "* `batch`: This is the batch size to use for the training epochs.\n",
    "* `prefetch`: Prefetching overlaps the preprocessing and model execution of a training step. While the model is executing training step s, the input pipeline is reading the data for step s+1. It can be used to decouple the time when data is produced from the time when data is consumed. The number of elements to prefetch can be managed by passing  `tf.data.AUTOTUNE`.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8d5d8",
   "metadata": {
    "id": "dca8d5d8"
   },
   "source": [
    "### 5.3 Load the Dataset in Memory and Create the Data Pipeline\n",
    "\n",
    "We will now use the two functions above to load the data in memory and create a data pipeline. Note that although the dataset is partitioned into train and test components, for demonstration purposes, we will simply use the test data as the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b2ef9",
   "metadata": {
    "id": "419b2ef9"
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR10 data into memory.\n",
    "(X_train, y_train), (X_test, y_test) = cifar10_from_keras()\n",
    "\n",
    "# Prepare the tf.data pipeline data from memory.\n",
    "train_ds = prepare_input_pipeline(X_train, y_train)\n",
    "valid_ds = prepare_input_pipeline(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5be1a4",
   "metadata": {
    "id": "9c5be1a4"
   },
   "source": [
    "### 5.5 Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1da7b5",
   "metadata": {
    "id": "aa1da7b5",
    "outputId": "269dd306-60b6-4e74-e663-289a9a69bbd9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FROM LOADING TF.DATA DATASET FROM MEMORY\n",
      "Epoch 1/11\n",
      "3125/3125 [==============================] - 16s 5ms/step - loss: 1.6105 - accuracy: 0.4152 - val_loss: 1.4704 - val_accuracy: 0.4709\n",
      "Epoch 2/11\n",
      "3125/3125 [==============================] - 15s 5ms/step - loss: 1.3493 - accuracy: 0.5129 - val_loss: 1.2931 - val_accuracy: 0.5324\n",
      "Epoch 3/11\n",
      "3125/3125 [==============================] - 16s 5ms/step - loss: 1.2470 - accuracy: 0.5561 - val_loss: 1.2964 - val_accuracy: 0.5418\n",
      "Epoch 4/11\n",
      "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1778 - accuracy: 0.5808 - val_loss: 1.2347 - val_accuracy: 0.5666\n",
      "Epoch 5/11\n",
      "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1195 - accuracy: 0.6022 - val_loss: 1.1937 - val_accuracy: 0.5784\n",
      "Epoch 6/11\n",
      "3125/3125 [==============================] - 17s 5ms/step - loss: 1.0705 - accuracy: 0.6218 - val_loss: 1.1301 - val_accuracy: 0.6017\n",
      "Epoch 7/11\n",
      "3125/3125 [==============================] - 17s 5ms/step - loss: 1.0325 - accuracy: 0.6344 - val_loss: 1.1185 - val_accuracy: 0.6100\n",
      "Epoch 8/11\n",
      "3125/3125 [==============================] - 17s 5ms/step - loss: 0.9914 - accuracy: 0.6503 - val_loss: 1.1293 - val_accuracy: 0.6088\n",
      "Epoch 9/11\n",
      "3125/3125 [==============================] - 18s 6ms/step - loss: 0.9615 - accuracy: 0.6602 - val_loss: 1.1051 - val_accuracy: 0.6178\n",
      "Epoch 10/11\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 0.9295 - accuracy: 0.6724 - val_loss: 1.1094 - val_accuracy: 0.6140\n",
      "Epoch 11/11\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 0.9020 - accuracy: 0.6832 - val_loss: 1.1003 - val_accuracy: 0.6230\n"
     ]
    }
   ],
   "source": [
    "# Compile the model for experiment 1.\n",
    "model = LeNet5_model(num_classes=DatasetConfig.NUM_CLASSES, \n",
    "                     shape=(DatasetConfig.IMG_HEIGHT, DatasetConfig.IMG_WIDTH, 3),\n",
    "                     print_model_summary=False)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(TrainingConfig.LEARNING_RATE), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "# Train experiment 1.\n",
    "print('TRAINING FROM LOADING TF.DATA DATASET FROM MEMORY')\n",
    "history_1 = model.fit(train_ds,\n",
    "                      epochs=TrainingConfig.EPOCHS,\n",
    "                      validation_data=valid_ds,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb24d7",
   "metadata": {
    "id": "e8cb24d7"
   },
   "source": [
    "## 6 Data Pipeline from File System\n",
    "\n",
    "Creating a data pipeline from data that resides on the file system requires two methods from the TensorFlow Data API.\n",
    "\n",
    "`tf.data.Dataset.list_files(path)`<br/>\n",
    "`tf.data.Dataset.map(map_func)`\n",
    "\n",
    "We first use `tf.data.Dataset.list_files()` to create a dataset object that contains file path references to the image files on disk. We then use the `tf.data.Dataset.map()` method which allows us to apply a user-defined function to process the images files on disk.\n",
    "\n",
    "First, we define the list of class names for the CIFAR10 dataset and specify he root path for the dataset on the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13071cfa",
   "metadata": {
    "id": "13071cfa"
   },
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce8e57",
   "metadata": {
    "id": "bdce8e57"
   },
   "outputs": [],
   "source": [
    "# Define the root path.\n",
    "cifar10_root = pathlib.Path('./cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1bc28",
   "metadata": {
    "id": "79c1bc28"
   },
   "source": [
    "### 6.1 Using `tf.data.Dataset.list_files()` to Create List Datasets\n",
    "\n",
    "Here, we use glob notation to obtain the path names to each image file in the dataset, and the `list_files()` method returns a`shuffleDataset` object that contains the pathnames stores as TensorFlow strings. Informally, we'll also refer to these objects as list datasets since they contain the list of pathnames to the image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905c03f",
   "metadata": {
    "id": "9905c03f",
    "outputId": "c9c9f3c7-d315-40d5-b06e-6ff0d20fbdc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'cifar10/train/ship/46944_ship.png', shape=(), dtype=string)\n",
      "tf.Tensor(b'cifar10/train/truck/44836_truck.png', shape=(), dtype=string)\n",
      "tf.Tensor(b'cifar10/train/automobile/28957_automobile.png', shape=(), dtype=string)\n",
      "tf.Tensor(b'cifar10/train/truck/43112_truck.png', shape=(), dtype=string)\n",
      "tf.Tensor(b'cifar10/train/cat/39885_cat.png', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Create the train and validation list datasets and check a few samples.\n",
    "train_list_ds = tf.data.Dataset.list_files(os.path.join(cifar10_root, 'train', '*', '*'))\n",
    "valid_list_ds = tf.data.Dataset.list_files(os.path.join(cifar10_root, 'test',  '*', '*'))\n",
    "\n",
    "# Print a few entries from train_list_ds.\n",
    "for file in train_list_ds.take(5):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c4ca4",
   "metadata": {
    "id": "391c4ca4"
   },
   "source": [
    "### 6.2 Define a Function to Process the Image Files in the List Datasets\n",
    "\n",
    "Next, we need to define a function that will process each of the image files in the list datasets we created above. The input signature of the function below is determined by the structure of each element in the list dataset (which is a file path to an image file). \n",
    "\n",
    "The function reads the image, decodes it from byte strings, and converts it to a `float32` tensor format. Next, we parse the file path to retrieve the class name (label) for the image sample. We then compare the `class_name` to the `class_names` list, which returns a boolean tensor which is then passed to the `argmax` function to determine the class ID (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c91c8a",
   "metadata": {
    "id": "f5c91c8a"
   },
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "\n",
    "    raw = tf.io.read_file(file_path)\n",
    "    image = tf.io.decode_image(raw)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    \n",
    "    # Parse the file path to retrieve the class name.\n",
    "    class_name = tf.strings.split(file_path, os.sep)[-2]\n",
    "    \n",
    "    # Compare the class name to the class names list to dertermine the class ID.\n",
    "    one_hot = class_name == class_names\n",
    "    label = tf.argmax(one_hot)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4aa1e",
   "metadata": {
    "id": "6ec4aa1e"
   },
   "source": [
    "### 6.3 Apply the Mapping Function to the List Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7ae1f",
   "metadata": {
    "id": "36d7ae1f"
   },
   "outputs": [],
   "source": [
    "# Apply the mapping function to the list datasets.\n",
    "train_ds = train_list_ds.map(process_path)\n",
    "valid_ds = valid_list_ds.map(process_path)\n",
    "\n",
    "# Optional, but highly recommended for improved performance. \n",
    "train_ds = (train_ds\n",
    "            .cache()\n",
    "            .shuffle(buffer_size=512)\n",
    "            .batch(TrainingConfig.BATCH_SIZE)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "           )\n",
    "\n",
    "valid_ds = valid_ds.batch(batch_size=TrainingConfig.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa268b",
   "metadata": {
    "id": "97aa268b"
   },
   "source": [
    "### 6.4 Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98397722",
   "metadata": {
    "id": "98397722",
    "outputId": "1301116b-6add-426c-a2c7-e76b247edca2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 28, 28, 6)         0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 14, 14, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10, 10, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "TRAINING FROM LOADING TF.DATA DATASET FROM DISK\n",
      "Epoch 1/11\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.6705 - accuracy: 0.3943 - val_loss: 1.4566 - val_accuracy: 0.4725\n",
      "Epoch 2/11\n",
      "3125/3125 [==============================] - 26s 8ms/step - loss: 1.3942 - accuracy: 0.4989 - val_loss: 1.3595 - val_accuracy: 0.5128\n",
      "Epoch 3/11\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.2888 - accuracy: 0.5395 - val_loss: 1.3168 - val_accuracy: 0.5302\n",
      "Epoch 4/11\n",
      "3125/3125 [==============================] - 29s 9ms/step - loss: 1.2075 - accuracy: 0.5729 - val_loss: 1.2297 - val_accuracy: 0.5663\n",
      "Epoch 5/11\n",
      "3125/3125 [==============================] - 30s 10ms/step - loss: 1.1342 - accuracy: 0.6018 - val_loss: 1.2149 - val_accuracy: 0.5726\n",
      "Epoch 6/11\n",
      "3125/3125 [==============================] - 30s 10ms/step - loss: 1.0771 - accuracy: 0.6208 - val_loss: 1.1948 - val_accuracy: 0.5803\n",
      "Epoch 7/11\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.0303 - accuracy: 0.6404 - val_loss: 1.1395 - val_accuracy: 0.6039\n",
      "Epoch 8/11\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.9820 - accuracy: 0.6539 - val_loss: 1.1441 - val_accuracy: 0.6088\n",
      "Epoch 9/11\n",
      "3125/3125 [==============================] - 29s 9ms/step - loss: 0.9406 - accuracy: 0.6735 - val_loss: 1.1519 - val_accuracy: 0.6068\n",
      "Epoch 10/11\n",
      "3125/3125 [==============================] - 29s 9ms/step - loss: 0.9025 - accuracy: 0.6838 - val_loss: 1.1466 - val_accuracy: 0.6075\n",
      "Epoch 11/11\n",
      "3125/3125 [==============================] - 30s 9ms/step - loss: 0.8680 - accuracy: 0.6958 - val_loss: 1.1329 - val_accuracy: 0.6143\n"
     ]
    }
   ],
   "source": [
    "# Compile the model for experiment 2.\n",
    "model = LeNet5_model(num_classes=DatasetConfig.NUM_CLASSES, \n",
    "                     shape=(DatasetConfig.IMG_HEIGHT, DatasetConfig.IMG_WIDTH, 3))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(TrainingConfig.LEARNING_RATE),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "# Train experiment 2.\n",
    "print('\\nTRAINING FROM LOADING TF.DATA DATASET FROM DISK')\n",
    "\n",
    "history_2 = model.fit(train_ds,\n",
    "                      epochs=TrainingConfig.EPOCHS,\n",
    "                      validation_data=valid_ds,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a364b",
   "metadata": {
    "id": "a42a364b"
   },
   "source": [
    "## 7 Training Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a38bc3",
   "metadata": {
    "id": "58a38bc3"
   },
   "outputs": [],
   "source": [
    "def plot_results(metrics, ylabel=None, ylim=None, metric_name=None, color=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "    if not (isinstance(metric_name, list) or isinstance(metric_name, tuple)):\n",
    "        metrics = [metrics,]\n",
    "        metric_name = [metric_name,]\n",
    "        \n",
    "    for idx, metric in enumerate(metrics):    \n",
    "        ax.plot(metric, color=color[idx])\n",
    "    \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(ylabel)\n",
    "    plt.xlim([0, TrainingConfig.EPOCHS-1])\n",
    "    plt.ylim(ylim)\n",
    "    # Tailor x-axis tick marks\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    plt.grid(True)\n",
    "    plt.legend(metric_name)   \n",
    "    plt.show(block=block_plot)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8030bf2",
   "metadata": {
    "id": "f8030bf2",
    "outputId": "55f0fd0f-43d2-4767-f46c-8678cefd2a65",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = history_1.history[\"accuracy\"]\n",
    "valid_acc = history_1.history[\"val_accuracy\"]\n",
    "\n",
    "plot_results([ train_acc, valid_acc ], \n",
    "            ylabel=\"Accuracy\",\n",
    "            ylim = [0.0, 1.0],\n",
    "            metric_name=[\"Training Accuracy\", \"Validation Accuracy\"],\n",
    "            color=[\"g\", \"b\"])\n",
    "\n",
    "train_acc = history_2.history[\"accuracy\"]\n",
    "valid_acc = history_2.history[\"val_accuracy\"]\n",
    "\n",
    "plot_results([ train_acc, valid_acc ], \n",
    "            ylabel=\"Accuracy\",\n",
    "            ylim = [0.0, 1.0],\n",
    "            metric_name=[\"Training Accuracy\", \"Validation Accuracy\"],\n",
    "            color=[\"g\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b0caa",
   "metadata": {
    "id": "175b0caa"
   },
   "source": [
    "## 8 Conclusion\n",
    "In this notebook, we learned how to use the `tf.data` API to build efficient input data pipelines for image data using `tf.data.Datasets`. We demonstrated how to do this from data stored in memory as well as for data that resides on the file system. In the next notebook, we'll demonstrate how to use the Sequence class in TensorFlow to create a custom data loader class that will be very helpful in the next module when we cover image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0bb74",
   "metadata": {
    "id": "e5f0bb74"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "c4_04_19_Introduction_to_TF_Data_RECORDED.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
